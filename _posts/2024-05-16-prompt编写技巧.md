---
layout: post
title: 大模型prompt最佳技巧-来自新加坡首届GPT-4提示工程大赛中夺冠者的分享
categories: [教程]
description: 大模型prompt最佳技巧
keywords: 大模型prompt, GPT-4提示词，提示词技巧，提示词教程
mermaid: false
sequence: false
flow: false
mathjax: false
mindmap: false
mindmap2: false
---

提示工程是一门将艺术与科学巧妙融合的学科 — 它不仅关乎技术的理解，更涉及创造力和战略思考。这里分享新加坡政府科技局（GovTech）举办的首届GPT-4提示工程大赛中夺冠者的提示词编写技巧与思考。
## 在新加坡首届GPT-4提示工程大赛中夺冠的秘诀

### 引言

在2023年12月28日，我有幸在新加坡政府科技局（GovTech）举办的首届GPT-4提示工程大赛中夺冠。这场比赛汇聚了400多名顶尖选手，是一场智慧与创造力的盛宴。在这篇文章中，我将分享我在驾驭大型语言模型（LLMs）过程中所学到的一些策略，这些策略能够精准地驱动任何大型语言模型为你服务，甚至做得更多！


### 主题概览

本文涵盖以下主题，其中 🔵 代表初学者友好的技巧，而 🔴 代表高级策略：

- 🔵 借助 CO-STAR 框架构建高效的提示
- 🔵 利用分隔符来分节构建提示
- 🔴 设计含有 LLM 保护机制的系统级提示
- 🔴 仅依靠大语言模型分析数据集，无需插件或代码 — 实际案例分析 Kaggle 的真实数据集

#### 1. 🔵 借助 CO-STAR 框架构建高效的提示

CO-STAR 框架是由新加坡政府科技局数据科学与 AI 团队创立的一个实用的提示构建工具。它考虑了所有影响大语言模型响应效果和相关性的关键因素，帮助你获得更优的反馈。


##### 如何应用 CO-STAR 框架：

- **(C)：（context）上下文**：为任务提供背景信息
- **(O)：（objective） 目标**：明确你要求大语言模型完成的任务
- **(S)：（style） 风格**：明确你期望的写作风格
- **(T)：（tone） 语气**：设置回应的情感调
- **(A)：（audience） 受众**：识别目标受众
- **(R)：（response） 响应**：规定输出的格式

##### CO-STAR 框架的实用示例

假设你担任社交媒体经理，需要草拟一条 Facebook 帖子，用以推广公司的新产品。通过运用 CO-STAR 框架，你可以确保 GPT-4 的响应变得更具针对性和效果。

未使用 CO-STAR 的快速提示可能是这样的：

> 为我的公司 Alpha 的新产品 Beta——一款新型超快速吹风机，撰写一条 Facebook 帖子。

这是 GPT-4 的回答：

> 介绍 Alpha 公司革命性的 Beta 吹风机！告别长时间、无聊的吹发过程！Alpha 公司自豪地推出 Beta，这是我们在护发技术上的最新创新——超快干燥：Beta 设计旨在让你的吹发时间减半，得益于其先进的强力马达。快速准备，享受更多你所爱的时间！立即购买：[产品页面链接]

下面是一个应用 CO-STAR 模板的示例:

```
# CONTEXT（上下文） #
我想推广公司的新产品。我的公司名为 Alpha，新产品名为 Beta，是一款新型超快速吹风机。

# OBJECTIVE（目标） #
帮我创建一条 Facebook 帖子，目的是吸引人们点击产品链接进行购买。

# STYLE（风格） #
参照 Dyson 等成功公司的宣传风格，它们在推广类似产品时的文案风格。

# TONE（语调） #
说服性

# AUDIENCE（受众） #
我们公司在 Facebook 上的主要受众是老年人。请针对这一群体在选择护发产品时的典型关注点来定制帖子。

# RESPONSE（响应） #
保持 Facebook 帖子简洁而深具影响力。
```

这是 GPT-4 的回答：

```
用 Alpha Beta——超快速吹风机，体验轻松的优雅生活，它是为具有洞察力的一代人设计的。

与 Alpha Beta 一起，重新找回简单而高效的护发乐趣。我们的最新创新不仅是一款吹风机；它还承诺为那些懂得欣赏生活美好事物的人提供快速、柔和且可靠的发型打理。

- 易用且直观：向复杂的设备说再见。Alpha Beta 专为舒适和简便而设计，非常适合那些喜欢简洁、无麻烦操作的人。- 节省时间的技术：我们知道您的时间非常宝贵。因此，Alpha Beta 显著缩短吹发时间，让您有更多时间享受生活。

每天都是与 Alpha Beta 相伴的美好发型日。立即体验优雅与简约的完美结合。

[您的产品链接在此]
```

#### 2. 🔵 使用分隔符进行文本分段

分隔符是特殊的符号，它们帮助大语言模型 (LLM) 辨识提示中哪些部分应当被视为一个完整的意义单元。通过设置分隔符，可以为这些 Token 序列提供结构，使特定部分得到不同的处理。

##### 分隔符的作用

分隔符可以是任何不常见组合的特殊字符序列，如：

- ***
- ===
- >>>

##### 分隔符使用的示例

```
请在 <<<CONVERSATIONS>>> 中对每段对话的情绪进行分类，标为‘正面’或‘负面’。仅提供情绪分类结果，不需任何引言。

对话示例

[Agent]: 早上好，今天我能为您做些什么？
[Customer]: 这个产品真差劲，一点都不符合广告宣传！
[Customer]: 我非常不满，要求全额退款。

[Agent]: 早安，我今天怎么为您服务？ [Customer]: 嗨，我只想说我真的很喜欢你们的产品。它超出了我的预期！

输出示例

负面

正面

<<<
[Agent]: 您好！欢迎使用我们的客服。今天有什么可以帮到您的？
[Customer]: 嗨，我只想让你知道我收到了订单，它非常棒！
[Agent]: 那太好了！我们很高兴您对购买感到满意。还有其他需要帮助的吗？
[Customer]: 不，就这些了。只是想表达一下我的好评。感谢您的优质服务！

[Agent]: 您好，感谢您联系我们。今天有什么可以帮助您的？
[Customer]: 我对最近的购买非常不满。这完全不是我所期待的。
[Agent]: 我很抱歉听到您有这样的体验。您能否提供更多细节，以便我为您提供帮助？
[Customer]: 产品质量不佳，而且送达晚了。我对这次购买感到非常不满。
>>>
```
在上述示例中，使用 ### 分隔符来分隔不同的部分，通过大写的章节标题如 对话示例 和 输出示例 进行区分。引言部分说明了要对 <<<CONVERSATIONS>>> 中的对话进行情绪分类，而这些对话在提示的底部给出，没有任何解释文本，但分隔符的存在让模型明白这些对话需要被分类。

GPT-4 的输出:

> 正面

> 负面

#### 3. 🔴 利用大语言模型 (LLM) 的系统提示创建机制

本节内容仅适用于具备系统提示功能的大语言模型 (LLM)，一般“系统提示”和“系统消息”是通过 API 编程方式交互时使用的术语，在使用API接口调用大模型时设置相关参数。

而“自定义指令”一般是指在网页界面上使用大模型时，我们在输入框输入的文本内容。

##### 系统提示一般包括以下几个部分：

- 任务定义
- 输出格式
- 操作边界

系统提示示例：
> 您需要用这段文本来回答问题：[插入文本]。请按照{"问题": "答案"} 的格式来回答。如果文本信息不足以回答问题，请以"NA"作答。您只能解答与[指定范围]相关的问题。请避免回答任何与年龄、性别及宗教等人口统计信息相关的问题。

那么用户在使用过程中，一般是在大模型网页对话界面上，输入的文本内容就是用户的提示词，一般会被插入到系统提示词中间，比如上面的[插入文本]这个占位符中。

#### 4. 🔴 仅用大语言模型 (LLM) 分析数据集，不借助插件或编码

你可能已经听说过 OpenAI 在 ChatGPT 的 GPT-4 中为付费账户提供的高级数据分析插件。但是，你知道吗？并不总是需要依赖这类插件来有效地使用大语言模型 (LLM) 分析数据集。

##### LLM 擅长的数据集分析类型

LLMs 在识别模式和趋势方面表现出色。这得益于它们在庞大且多样化的数据上接受的广泛训练，能够洞察到复杂的模式，这些模式可能不是一眼就能看出来的。

这使它们非常适合执行基于模式查找的任务，例如：

- 异常检测
- 聚类
- 跨列关系
- 文本分析（适用于文本列）
- 趋势分析（针对有时间维度的数据集）

##### LLM 不擅长的数据集分析类型  

LLMs 在执行精确的数学计算方面有所限制，这让它们不适合需要精确量化分析的任务，比如：

- 描述性统计（Descriptive Statistics）： 通过如均值或方差等措施定量总结数值列。
- 相关性分析（Correlation Analysis）： 获取列间的精确相关系数。
- 统计分析（Statistical Analysis）： 例如进行假设检验，判断数据点组间是否存在统计显著的差异。
- 机器学习（Machine Learning）： 在数据集上执行预测模型，如使用线性回归、梯度增强树或神经网络。

正是为了执行这些量化任务，OpenAI 推出了高级数据分析插件，以便通过编程语言在数据集上运行代码。  

##### 仅使用 LLM 分析 Kaggle 数据集

我们将使用一个流行的实际 Kaggle 数据集，该数据集专为客户个性分析而设计，帮助公司对客户基础进行细分，从而更好地了解客户。

为了之后验证 LLM 分析的方便，我们将这个数据集缩减至 50 行，并仅保留最相关的几列。

设想你是公司营销团队的一员，你的任务是利用这份客户信息数据集来指导营销活动。这是一个分两步的任务：首先，利用数据集生成有意义的客户细分；其次，针对每个细分提出最佳的市场营销策略。这是一个实际的商业问题，其中第一步的模式识别能力是 LLM 可以大显身手的地方。

我们将按以下方式设计任务提示，采用四种提示工程技术（更多详情）：

1. 将复杂任务分解成简单步骤；
2. 引用每个步骤的中间输出；
3. 格式化 LLM 的回答；
4. 将指令与数据集分离。

```
系统提示：
我希望你扮演数据科学家的角色来分析数据集。不要编造数据集中不存在的信息。对于我提出的每个分析要求，提供确切且确定的答案，不要提供代码或指导在其他平台上进行分析的方法。

提示：
# CONTEXT #
我销售葡萄酒。我手头有一个客户信息数据集：[出生年份，婚姻状况，收入，子女数量，上次购买至今天数，消费金额]。

#############

# OBJECTIVE #
我希望你利用这个数据集将我的客户分组，并为每个群组制定营销策略。遵循以下分步骤，且不使用代码：

1. CLUSTERS: 根据数据集的列将客户分组，确保同一群组内的客户在列值上相似，不同群组的客户在列值上明显不同。确保每一行数据只属于一个群组。

对于每个发现的群组，
2. CLUSTER_INFORMATION: 根据数据集的列来描述群组。
3. CLUSTER_NAME: 根据[CLUSTER_INFORMATION]解读得出该客户群组的简称。
4. MARKETING_IDEAS: 提出针对该客户群组的市场营销策略。
5. RATIONALE: 解释为什么[MARKETING_IDEAS]对这个客户群组有效且相关。

#############

# STYLE #
商业分析报告

#############

# TONE #
专业、技术性

#############

# AUDIENCE #
我的商业伙伴们。让他们相信你的营销策略是深思熟虑的，并且有充分的数据支持。

#############

# RESPONSE: MARKDOWN REPORT #
<对[CLUSTERS]中的每一个群组> — 客户群组：[CLUSTER_NAME] — 群组档案：[CLUSTER_INFORMATION] — 营销策略：[MARKETING_IDEAS] — 理由：[RATIONALE]

<附录>
提供一个表格，列出每个群组中的行号，以支持你的分析。表头如下：[[CLUSTER_NAME], 行号列表]。

#############

# START ANALYSIS #
如果你已经明白，请向我索要我的数据集。
```

#### 何时应当用大语言模型 (LLM) 来分析数据集？

对于需要精确的数学运算或复杂的规则处理的任务，传统的编程方法依然更加适用。

而对于依赖模式识别的任务，传统的编程和算法处理可能更加困难且耗时。大语言模型在这类任务中表现优异，能提供包括分析附件在内的额外输出，并能生成 Markdown 格式的完整分析报告。

总的来说，是否采用大语言模型取决于任务本身的性质，需要平衡其在模式识别上的强项与传统编程技术提供的精确度和特定性。

##### 高质量数据分析提示词示例：

```
# CONTEXT #
我经营葡萄酒生意。我手头有一份包含客户信息的数据集：[出生年份，婚姻状况，收入，子女数目，自上次购买至今天数，消费金额]。

#############

# OBJECTIVE #
我希望你利用这份数据集将我的客户进行分组，随后为我提供针对每个群体的市场营销策略。请按以下步骤操作，且不要编写代码：

1. CLUSTERS: 利用数据集中的列值对行数据进行聚类，确保同一聚类内的客户在列值上保持相似，而不同聚类的客户则明显不同。确保每一行数据只属于一个聚类。

对于每个确定的聚类，
2. CLUSTER_INFORMATION: 描述聚类的特征。
3. CLUSTER_NAME: 根据[CLUSTER_INFORMATION]解读，为这个客户群体起一个简称。
4. MARKETING_IDEAS: 提出针对此群体的营销策略。
5. RATIONALE: 解释这些[MARKETING_IDEAS]为何对此群体有效。

#############

# STYLE #
商业分析报告

#############

# TONE #
专业，技术性

#############

# AUDIENCE #
面向我的商业伙伴。让他们确信你的营销策略是经过深思熟虑的，并完全得到数据支持。

#############

# RESPONSE: MARKDOWN REPORT #
<对于[CLUSTERS]中的每个聚类>
— 客户群组：[CLUSTER_NAME]
— 简介：[CLUSTER_INFORMATION]
— 营销想法：[MARKETING_IDEAS]
— 理由：[RATIONALE]

<附录> 提供一个表格，记录每个聚类的行号，以佐证你的分析。表头如下：[[CLUSTER_NAME], 行号列表]。

#############

# START ANALYSIS #
如果你已经理解，请向我请求我的数据集。

```
#### 提示词技巧总结

##### 技巧 1：将复杂任务简化成步骤

大语言模型（LLM）擅长处理简单的任务，对于复杂的任务则表现不佳。因此，在面对复杂任务时，把它分解成一步步简单的指令是至关重要的。这种方法的核心思想是，明确告知 LLM 你自己执行该任务时会采取的每一个步骤。

例如，具体步骤如下：

请按照这个步骤操作，不要使用编码：

1. 数据聚类（CLUSTERS）：利用数据集的各列特征，将数据行进行聚类，确保同一聚类中的客户在这些特征上相似，而不同聚类的客户则明显不同。每条数据只能属于一个聚类。
对于每个聚类，
2. 聚类描述（CLUSTER_INFORMATION）：描述聚类的特点。
3. 聚类命名（CLUSTER_NAME）：根据聚类描述，为这个客户群体起一个简洁的名字。
4. 营销策略（MARKETING_IDEAS）：为这个客户群体制定营销策略。
5. 策略解释（RATIONALE）：说明为什么这些营销策略对这个客户群体有效。

这样的分步指导，比起直接要求 LLM“对客户进行分组并提出营销策略”的方式，能显著提高其输出的准确性。

##### 技巧 2：标记并引用中间输出

在提供步骤时，我们会用大写字母标记每个步骤的输出，例如数据聚类（CLUSTERS）、聚类描述（CLUSTER_INFORMATION）、聚类命名（CLUSTER_NAME）、营销策略（MARKETING_IDEAS）和策略解释（RATIONALE）。这样做是为了区分指令中的变量名和其他文本，方便后续引用这些中间输出。

##### 技巧 3：优化响应格式
此处我们请求一个 Markdown 格式的报告，以增强响应的可读性和结构性。利用中间步骤的变量名，可以明确报告的构架。
```
# 响应：Markdown 报告 #
<对每个数据聚类[数据聚类（CLUSTERS）]>
— 客户群体：[聚类命名（CLUSTER_NAME）]
— 群体特征：[聚类描述（CLUSTER_INFORMATION）]
— 营销策略：[营销策略（MARKETING_IDEAS）]
— 策略说明：[策略解释（RATIONALE）]

<附录> 提供一个表格，记录每个聚类包含的数据行号，以验证分析的准确性。表格标题为：[聚类命名（CLUSTER_NAME）, 行号列表]。
```

此外，你还可以让 ChatGPT 将报告以可下载文件形式提供，便于你在编写最终报告时参考使用。

##### 技巧 4：将任务指令与数据集分离
在我们的首个提示中，你会发现我们并没有直接将数据集交给大语言模型（LLM）。反而，提示只给出了数据集分析的任务指令，并在底部添加了这样的话：
```
# START ANALYSIS #
如果你明白了，请向我请求数据集。
```
###### 为什么需要将指令与数据集分开处理呢？

这样做可以帮助大语言模型更清晰地理解各自的内容，降低遗漏信息的风险，尤其是在指令较多且复杂的任务中。你可能遇到过这样的情况：在一个长的提示中提出的某个指令被“偶然遗忘”了——例如，你请求一个 100 字的回答，但大语言模型却给出了更长的段落。通过先接收指令，再处理这些指令所对应的数据集，大语言模型可以更好地消化它应该做的事情，然后再执行相关的数据操作。

值得注意的是，这种指令与数据集的分离只能在可以维护对话记忆的聊天型大语言模型中实现，而非那些没有这种记忆功能的完成型模型。


