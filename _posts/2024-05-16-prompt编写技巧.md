---
layout: post
title: 大模型prompt最佳技巧-来自新加坡首届GPT-4提示工程大赛中夺冠者的分享
categories: [教程]
description: 大模型prompt最佳技巧
keywords: 大模型prompt, GPT-4提示词，提示词技巧，提示词教程
mermaid: false
sequence: false
flow: false
mathjax: false
mindmap: false
mindmap2: false
---

提示工程是一门将艺术与科学巧妙融合的学科 — 它不仅关乎技术的理解，更涉及创造力和战略思考。这里分享新加坡政府科技局（GovTech）举办的首届GPT-4提示工程大赛中夺冠者的提示词编写技巧与思考。
## 在新加坡首届GPT-4提示工程大赛中夺冠的秘诀

#### 引言

在2023年12月28日，我有幸在新加坡政府科技局（GovTech）举办的首届GPT-4提示工程大赛中夺冠。这场比赛汇聚了400多名顶尖选手，是一场智慧与创造力的盛宴。在这篇文章中，我将分享我在驾驭大型语言模型（LLMs）过程中所学到的一些策略，这些策略能够精准地驱动任何大型语言模型为你服务，甚至做得更多！


#### 主题概览

本文涵盖以下主题，其中 🔵 代表初学者友好的技巧，而 🔴 代表高级策略：

- 🔵 借助 CO-STAR 框架构建高效的提示
- 🔵 利用分隔符来分节构建提示
- 🔴 设计含有 LLM 保护机制的系统级提示
- 🔴 仅依靠大语言模型分析数据集，无需插件或代码 — 实际案例分析 Kaggle 的真实数据集

###### 1. 🔵 借助 CO-STAR 框架构建高效的提示

CO-STAR 框架是由新加坡政府科技局数据科学与 AI 团队创立的一个实用的提示构建工具。它考虑了所有影响大语言模型响应效果和相关性的关键因素，帮助你获得更优的反馈。


######## 如何应用 CO-STAR 框架：

- **(C)：（context）上下文**：为任务提供背景信息
- **(O)：（objective） 目标**：明确你要求大语言模型完成的任务
- **(S)：（style） 风格**：明确你期望的写作风格
- **(T)：（tone） 语气**：设置回应的情感调
- **(A)：（audience） 受众**：识别目标受众
- **(R)：（response） 响应**：规定输出的格式

######## CO-STAR 框架的实用示例

假设你担任社交媒体经理，需要草拟一条 Facebook 帖子，用以推广公司的新产品。通过运用 CO-STAR 框架，你可以确保 GPT-4 的响应变得更具针对性和效果。

未使用 CO-STAR 的快速提示可能是这样的：

> 为我的公司 Alpha 的新产品 Beta——一款新型超快速吹风机，撰写一条 Facebook 帖子。

这是 GPT-4 的回答：

> 介绍 Alpha 公司革命性的 Beta 吹风机！告别长时间、无聊的吹发过程！Alpha 公司自豪地推出 Beta，这是我们在护发技术上的最新创新——超快干燥：Beta 设计旨在让你的吹发时间减半，得益于其先进的强力马达。快速准备，享受更多你所爱的时间！立即购买：[产品页面链接]

下面是一个应用 CO-STAR 模板的示例:

```# CONTEXT（上下文） #
我想推广公司的新产品。我的公司名为 Alpha，新产品名为 Beta，是一款新型超快速吹风机。

# OBJECTIVE（目标） #
帮我创建一条 Facebook 帖子，目的是吸引人们点击产品链接进行购买。

# STYLE（风格） #
参照 Dyson 等成功公司的宣传风格，它们在推广类似产品时的文案风格。

# TONE（语调） #
说服性

# AUDIENCE（受众） #
我们公司在 Facebook 上的主要受众是老年人。请针对这一群体在选择护发产品时的典型关注点来定制帖子。

# RESPONSE（响应） #
保持 Facebook 帖子简洁而深具影响力。
```
这是 GPT-4 的回答：
```
用 Alpha Beta——超快速吹风机，体验轻松的优雅生活，它是为具有洞察力的一代人设计的。

与 Alpha Beta 一起，重新找回简单而高效的护发乐趣。我们的最新创新不仅是一款吹风机；它还承诺为那些懂得欣赏生活美好事物的人提供快速、柔和且可靠的发型打理。

- 易用且直观：向复杂的设备说再见。Alpha Beta 专为舒适和简便而设计，非常适合那些喜欢简洁、无麻烦操作的人。- 节省时间的技术：我们知道您的时间非常宝贵。因此，Alpha Beta 显著缩短吹发时间，让您有更多时间享受生活。

每天都是与 Alpha Beta 相伴的美好发型日。立即体验优雅与简约的完美结合。

[您的产品链接在此]
```

###### 2. 🔵 使用分隔符进行文本分段

分隔符是特殊的符号，它们帮助大语言模型 (LLM) 辨识提示中哪些部分应当被视为一个完整的意义单元。通过设置分隔符，可以为这些 Token 序列提供结构，使特定部分得到不同的处理。

######## 分隔符的作用

分隔符可以是任何不常见组合的特殊字符序列，如：

- ***
- ===
- >>>

######## 分隔符使用的示例

```
请在 <<<CONVERSATIONS>>> 中对每段对话的情绪进行分类，标为‘正面’或‘负面’。仅提供情绪分类结果，不需任何引言。

对话示例

[Agent]: 早上好，今天我能为您做些什么？
[Customer]: 这个产品真差劲，一点都不符合广告宣传！
[Customer]: 我非常不满，要求全额退款。

[Agent]: 早安，我今天怎么为您服务？ [Customer]: 嗨，我只想说我真的很喜欢你们的产品。它超出了我的预期！

输出示例

负面

正面

<<<
[Agent]: 您好！欢迎使用我们的客服。今天有什么可以帮到您的？
[Customer]: 嗨，我只想让你知道我收到了订单，它非常棒！
[Agent]: 那太好了！我们很高兴您对购买感到满意。还有其他需要帮助的吗？
[Customer]: 不，就这些了。只是想表达一下我的好评。感谢您的优质服务！

[Agent]: 您好，感谢您联系我们。今天有什么可以帮助您的？
[Customer]: 我对最近的购买非常不满。这完全不是我所期待的。
[Agent]: 我很抱歉听到您有这样的体验。您能否提供更多细节，以便我为您提供帮助？
[Customer]: 产品质量不佳，而且送达晚了。我对这次购买感到非常不满。
>>>
```
在上述示例中，使用 ### 分隔符来分隔不同的部分，通过大写的章节标题如 对话示例 和 输出示例 进行区分。引言部分说明了要对 <<<CONVERSATIONS>>> 中的对话进行情绪分类，而这些对话在提示的底部给出，没有任何解释文本，但分隔符的存在让模型明白这些对话需要被分类。

GPT-4 的输出:
> 正面
> 负面

###### 3. 🔴 利用大语言模型 (LLM) 的系统提示创建机制

系统提示是您向大语言模型提供的关于其应如何响应的额外指示。这被视为一种额外的提示，因为它超出了您对大语言模型的常规用户提示。

######## 系统提示一般包括以下几个部分：

- 任务定义
- 输出格式
- 操作边界

###### 4. 🔴 仅用大语言模型 (LLM) 分析数据集，不借助插件或编码

你可能已经听说过 OpenAI 在 ChatGPT 的 GPT-4 中为付费账户提供的高级数据分析插件。但是，你知道吗？并不总是需要依赖这类插件来有效地使用大语言模型 (LLM) 分析数据集。

######## LLM 擅长的数据集分析类型

- 异常检测
- 聚类
- 跨列关系
- 文本分析（适用于文本列）
- 趋势分析（针对有时间维度的数据集）

######## 仅使用 LLM 分析 Kaggle 数据集

我们将使用一个流行的实际 Kaggle 数据集，该数据集专为客户个性分析而设计，帮助公司对客户基础进行细分，从而更好地了解客户。

#### 结语

通过本文，我们深入探讨了在新加坡首届GPT-4提示工程大赛中夺冠的秘诀。从CO-STAR框架的应用到分隔符的使用，再到系统提示的创建和数据集分析，这些策略不仅适用于初学者，也能为有一定基础的AI领域专家提供新的视角。希望这些分享能够激发你的创造力，帮助你在未来的AI挑战中取得成功！
